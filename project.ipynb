{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8fe208b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0ce5f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting a subset of 20,000 images to train, calibrate and test\n",
    "# Shuffling the dataset to remove patterns/groups of related images\n",
    "import random\n",
    "random.seed(10) # comment out later\n",
    "img_index = [i for i in range(20000)]\n",
    "random.shuffle(img_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "08d21ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing attributes Smiling, Male, Young.. for each image\n",
    "import pandas as pd\n",
    "df = pd.read_csv('list_attr_celeba.txt', skiprows=1, header=0, sep='\\s+')\n",
    "\n",
    "img_df = df[[\"Smiling\", \"Male\", \"Young\", \"Blond_Hair\"]].head(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c6f5946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings file ’embeddings.npy’ already exists. Skipping feature extraction.\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "def extract_features():\n",
    "    \"\"\"\n",
    "    Extracts features from images using a pre-trained Vision Transformer (ViT)\n",
    "    and saves them to a file.\n",
    "    \"\"\"\n",
    "    EMBEDDINGS_FILE = 'embeddings.npy'\n",
    "    IMAGE_DIR = 'celeba_selection'\n",
    "    NUM_IMAGES_TO_PROCESS = 20000 #later change to SAMPLE_SIZE\n",
    "    random.seed(10) # comment out later, for reproducibility\n",
    "\n",
    "    if os.path.exists(EMBEDDINGS_FILE):\n",
    "        print(f\"Embeddings file ’{EMBEDDINGS_FILE}’ already exists. Skipping feature extraction.\")\n",
    "        return\n",
    "    print(\"Starting feature extraction with Vision Transformer...\")\n",
    "\n",
    "    # 1. Load pre-trained Vision Transformer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vit = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1).to(device)\n",
    "    vit.eval() # Set model to evaluation mode\n",
    "\n",
    "    # 2. Define preprocessing steps consistent with ImageNet training\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # 3. Get the list of images to process\n",
    "\n",
    "    image_list = sorted(os.listdir(IMAGE_DIR))[:NUM_IMAGES_TO_PROCESS]\n",
    "    all_features = []\n",
    "\n",
    "    # 4. Extract embeddings for each image\n",
    "    with torch.no_grad():\n",
    "        for fname in tqdm(image_list, desc=\"Extracting ViT Embeddings\"):\n",
    "            img = Image.open(os.path.join(IMAGE_DIR, fname)).convert(\"RGB\")\n",
    "            x = preprocess(img).unsqueeze(0).to(device)\n",
    "            # Manually replicate the forward pass to get the features before the\n",
    "            # classification head, as the internal API (like .process_input)\n",
    "            # can change.\n",
    "            # 1. Process input using the private _process_input method\n",
    "            x_processed = vit._process_input(x)\n",
    "            n = x_processed.shape[0]\n",
    "            # 2. Add the class token\n",
    "            batch_class_token = vit.class_token.expand(n, -1, -1)\n",
    "            x_with_token = torch.cat([batch_class_token, x_processed], dim=1)\n",
    "            # 3. Pass through the encoder\n",
    "            encoded_features = vit.encoder(x_with_token)\n",
    "            # 4. Get the class token’s output (this is the feature vector)\n",
    "            features = encoded_features[:, 0]\n",
    "            all_features.append(features.cpu().numpy().flatten())\n",
    "    all_features_np = np.array(all_features)\n",
    "    print(f\"Feature matrix shape: {all_features_np.shape}\")\n",
    "    \n",
    "    # 5. Save embeddings for later use\n",
    "    np.save(EMBEDDINGS_FILE, all_features_np)\n",
    "    print(f\"Embeddings saved to ’{EMBEDDINGS_FILE}’.\")\n",
    "\n",
    "extract_features()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partitioning the data into training/calibration/test data\n",
    "embeddings = np.load(\"embeddings.npy\")\n",
    "\n",
    "SAMPLE_SIZE = 20000\n",
    "\n",
    "TRAIN_RATIO = 0.7\n",
    "CALIBRATION_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "train_index = int(TRAIN_RATIO * SAMPLE_SIZE)\n",
    "calibration_index = train_index + int(CALIBRATION_RATIO * SAMPLE_SIZE)\n",
    "\n",
    "# note - shuffle with labels later\n",
    "train_embed, calibration_embed, test_embed = np.split(embeddings, [train_index, calibration_index]) \n",
    "train_labels = img_df.iloc[:train_index]\n",
    "calibration_labels = img_df.iloc[train_index:calibration_index]\n",
    "test_labels = img_df.iloc[calibration_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d48d13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling the Naive Bayes Model\n",
    "train_embed_df = pd.DataFrame(train_embed)\n",
    "\n",
    "def calc_mean_sd(label):\n",
    "    # temp_df = train_embed_df.assign(label=train_labels[label].values)\n",
    "    temp_df = train_embed_df.copy()\n",
    "    temp_df['label'] = train_labels[label].values\n",
    "\n",
    "    dict_mean_sd = {}\n",
    "\n",
    "    for c in [-1, 1]:\n",
    "        feature_class = temp_df[temp_df['label'] == c].iloc[:, :-1]\n",
    "        means = feature_class.mean().values\n",
    "        sds = feature_class.std().values\n",
    "        dict_mean_sd[c] = [means, sds]\n",
    "\n",
    "    return dict_mean_sd\n",
    "\n",
    "stats = calc_mean_sd(\"Smiling\")\n",
    "\n",
    "# We model each feature (conditioned on label) under a gaussian distribution\n",
    "def pd_gaussian(x, mean, sd):  \n",
    "    var = math.pow(sd,2)\n",
    "    exponent = -((math.pow(x - mean, 2)) / (2 * var))\n",
    "    return (1 / math.sqrt(2 * math.pi * var)) * math.exp(exponent)\n",
    "\n",
    "\n",
    "def naive_bayes_class(feature, label):\n",
    "    # calc bayes prob for both classes of label\n",
    "    # compare both\n",
    "    pos = naive_bayes(feature, label, 1)\n",
    "    neg = naive_bayes(feature, label, -1)\n",
    "    classification = 1 if pos > neg else 0\n",
    "    return classification\n",
    "\n",
    "\n",
    "def naive_bayes(feature, label, label_class):\n",
    "    return likelihood(feature, label, label_class) + math.log(prior(label, label_class))\n",
    "\n",
    "\n",
    "# Returns probability a sample is given a particular label/class \n",
    "def prior(label, label_class):\n",
    "    label_count = train_labels[label].value_counts()[label_class]\n",
    "    return (label_count/len(train_labels))\n",
    "\n",
    "\n",
    "# Returns conditional probability a feature is present given a label and class\n",
    "def likelihood(feature, label, label_class):  \n",
    "    likelihood_total = 0\n",
    "    means = stats[label_class][0]\n",
    "    sds = stats[label_class][1]\n",
    "\n",
    "    for i in range(len(feature)):\n",
    "        likelihood_total += math.log(pd_gaussian(feature[i], means[i], sds[i]))\n",
    "\n",
    "    return likelihood_total\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "f770eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-433.94303278871433 -438.4729528886568\n",
      "0.5146666666666667\n"
     ]
    }
   ],
   "source": [
    "# Calculating accuracy for smiling\n",
    "\n",
    "\"\"\" \n",
    "    label - string\n",
    "    ground_truth - pandas series\n",
    "    set - numpy array\n",
    "\"\"\"\n",
    "def accuracy(label, ground_truth, set):\n",
    "    ground_truth = ground_truth[\"Smiling\"].replace(-1, 0)\n",
    "    correct_pred = 0\n",
    "    for i in range(len(set)):\n",
    "        pred = naive_bayes_class(set[i], label)\n",
    "        if pred == ground_truth.iloc[i]:\n",
    "            correct_pred += 1\n",
    "\n",
    "    accuracy = correct_pred / len(set)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "feature = train_embed[1202]  # pick first sample\n",
    "pos_likelihood = naive_bayes(feature, \"Smiling\", 1)\n",
    "neg_likelihood = naive_bayes(feature, \"Smiling\", -1)\n",
    "print(pos_likelihood, neg_likelihood)\n",
    "\n",
    "# Training accuracy\n",
    "print(accuracy(\"Smiling\", test_labels, test_embed))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test accuracy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
